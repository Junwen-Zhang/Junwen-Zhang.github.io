<!DOCTYPE html>
<html lang=zh>
<head>
    <!-- so meta -->
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="HandheldFriendly" content="True">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=5" />
    <meta name="description" content="作用：映射神经网络，找到最优的数据重用工作流。 原理   image-20230316120500047  如何使用 00-model-conv1d-1level  通过文件timeloop-model.accelergy.log可知，timeloop生成映射后会自动调用accelergy，将输入的architecture通过catci组件评估。   image-20230">
<meta property="og:type" content="article">
<meta property="og:title" content="TimeLoop">
<meta property="og:url" content="http://example.com/2023/03/16/TimeLoop/index.html">
<meta property="og:site_name" content="June文的小站">
<meta property="og:description" content="作用：映射神经网络，找到最优的数据重用工作流。 原理   image-20230316120500047  如何使用 00-model-conv1d-1level  通过文件timeloop-model.accelergy.log可知，timeloop生成映射后会自动调用accelergy，将输入的architecture通过catci组件评估。   image-20230">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://example.com/2023/03/16/TimeLoop/image-20230316120500047.png">
<meta property="og:image" content="http://example.com/2023/03/16/TimeLoop/image-20230215163226554.png">
<meta property="og:image" content="http://example.com/2023/03/16/TimeLoop/image-20230215162913799.png">
<meta property="og:image" content="http://example.com/2023/03/16/TimeLoop/image-20230215161827393.png">
<meta property="og:image" content="http://example.com/2023/03/16/TimeLoop/image-20230215164012799.png">
<meta property="og:image" content="http://example.com/2023/03/16/TimeLoop/image-20230215163758778.png">
<meta property="og:image" content="http://example.com/2023/03/16/TimeLoop/image-20230215170843695.png">
<meta property="og:image" content="http://example.com/2023/03/16/TimeLoop/image-20230215171153214.png">
<meta property="og:image" content="http://example.com/2023/03/16/TimeLoop/image-20230215175930634.png">
<meta property="og:image" content="http://example.com/2023/03/16/TimeLoop/image-20230225144923476.png">
<meta property="og:image" content="http://example.com/2023/03/16/TimeLoop/image-20230225145210890.png">
<meta property="og:image" content="http://example.com/2023/03/16/TimeLoop/image-20230215181203973.png">
<meta property="og:image" content="http://example.com/2023/03/16/TimeLoop/image-20230225174724380.png">
<meta property="og:image" content="http://example.com/2023/03/16/TimeLoop/image-20230225174059773.png">
<meta property="og:image" content="http://example.com/2023/03/16/TimeLoop/image-20230215181715931.png">
<meta property="og:image" content="http://example.com/2023/03/16/TimeLoop/image-20230225220028110.png">
<meta property="article:published_time" content="2023-03-16T03:58:08.000Z">
<meta property="article:modified_time" content="2023-03-17T12:48:08.758Z">
<meta property="article:author" content="JuneWen">
<meta property="article:tag" content="模拟器">
<meta property="article:tag" content="DNN加速器">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/2023/03/16/TimeLoop/image-20230316120500047.png">
    
    
      
        
          <link rel="shortcut icon" href="/images/favicon.ico">
        
      
      
        
          <link rel="icon" type="image/png" href="/images/favicon-192x192.png" sizes="192x192">
        
      
      
        
          <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png">
        
      
    
    <!-- title -->
    <title>TimeLoop</title>
    <!-- styles -->
    
<link rel="stylesheet" href="/css/style.css">

    <!-- persian styles -->
    
    <!-- rss -->
    
    
	<!-- mathjax -->
	
		<script type="text/x-mathjax-config">
		  MathJax.Hub.Config({
			tex2jax: {
			  skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
			  inlineMath: [['$','$']]
			}
		  });
		</script>
		<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-MML-AM_CHTML' async></script>
	
<meta name="generator" content="Hexo 5.4.2"></head>

<body class="max-width mx-auto px3 ltr">
    
      <div id="header-post">
  <a id="menu-icon" href="#" aria-label="目录"><i class="fas fa-bars fa-lg"></i></a>
  <a id="menu-icon-tablet" href="#" aria-label="目录"><i class="fas fa-bars fa-lg"></i></a>
  <a id="top-icon-tablet" href="#" aria-label="顶部" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');" style="display:none;"><i class="fas fa-chevron-up fa-lg"></i></a>
  <span id="menu">
    <span id="nav">
      <ul>
        <!--
       --><li><a href="/">首页</a></li><!--
     --><!--
       --><li><a href="/about/">关于</a></li><!--
     --><!--
       --><li><a href="/search/">搜索</a></li><!--
     --><!--
       --><li><a href="/archives/">归档</a></li><!--
     --><!--
       --><li><a href="/tags/">tags</a></li><!--
     --><!--
       --><li><a href="/categories/">categories</a></li><!--
     --><!--
       --><li><a target="_blank" rel="noopener" href="http://github.com/Junwen-Zhang">项目</a></li><!--
     -->
      </ul>
    </span>
    <br/>
    <span id="actions">
      <ul>
        
        <li><a class="icon" aria-label="上一篇" href="/2023/03/18/%E5%8D%9A%E5%A3%AB%E8%AE%BA%E6%96%87%E2%80%94%E2%80%94%E9%9D%A2%E5%90%91%E5%88%86%E5%B8%83%E5%BC%8F%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%95%B0%E6%8D%AE%E4%B8%AD%E5%BF%83%E7%BD%91%E7%BB%9C%E6%8B%93%E6%89%91%E4%BC%98%E5%8C%96%E5%92%8C%E6%B5%81%E9%87%8F%E8%B0%83%E5%BA%A6-%E7%8E%8B%E5%B8%85/"><i class="fas fa-chevron-left" aria-hidden="true" onmouseover="$('#i-prev').toggle();" onmouseout="$('#i-prev').toggle();"></i></a></li>
        
        
        <li><a class="icon" aria-label="下一篇" href="/2023/03/15/SparseLoop%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/"><i class="fas fa-chevron-right" aria-hidden="true" onmouseover="$('#i-next').toggle();" onmouseout="$('#i-next').toggle();"></i></a></li>
        
        <li><a class="icon" aria-label="返回顶部" href="#" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');"><i class="fas fa-chevron-up" aria-hidden="true" onmouseover="$('#i-top').toggle();" onmouseout="$('#i-top').toggle();"></i></a></li>
        <li><a class="icon" aria-label="分享文章" href="#"><i class="fas fa-share-alt" aria-hidden="true" onmouseover="$('#i-share').toggle();" onmouseout="$('#i-share').toggle();" onclick="$('#share').toggle();return false;"></i></a></li>
      </ul>
      <span id="i-prev" class="info" style="display:none;">上一篇</span>
      <span id="i-next" class="info" style="display:none;">下一篇</span>
      <span id="i-top" class="info" style="display:none;">返回顶部</span>
      <span id="i-share" class="info" style="display:none;">分享文章</span>
    </span>
    <br/>
    <div id="share" style="display: none">
      <ul>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.facebook.com/sharer.php?u=http://example.com/2023/03/16/TimeLoop/"><i class="fab fa-facebook " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://twitter.com/share?url=http://example.com/2023/03/16/TimeLoop/&text=TimeLoop"><i class="fab fa-twitter " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.linkedin.com/shareArticle?url=http://example.com/2023/03/16/TimeLoop/&title=TimeLoop"><i class="fab fa-linkedin " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://pinterest.com/pin/create/bookmarklet/?url=http://example.com/2023/03/16/TimeLoop/&is_video=false&description=TimeLoop"><i class="fab fa-pinterest " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="mailto:?subject=TimeLoop&body=Check out this article: http://example.com/2023/03/16/TimeLoop/"><i class="fas fa-envelope " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://getpocket.com/save?url=http://example.com/2023/03/16/TimeLoop/&title=TimeLoop"><i class="fab fa-get-pocket " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://reddit.com/submit?url=http://example.com/2023/03/16/TimeLoop/&title=TimeLoop"><i class="fab fa-reddit " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.stumbleupon.com/submit?url=http://example.com/2023/03/16/TimeLoop/&title=TimeLoop"><i class="fab fa-stumbleupon " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://digg.com/submit?url=http://example.com/2023/03/16/TimeLoop/&title=TimeLoop"><i class="fab fa-digg " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.tumblr.com/share/link?url=http://example.com/2023/03/16/TimeLoop/&name=TimeLoop&description="><i class="fab fa-tumblr " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://news.ycombinator.com/submitlink?u=http://example.com/2023/03/16/TimeLoop/&t=TimeLoop"><i class="fab fa-hacker-news " aria-hidden="true"></i></a></li>
</ul>

    </div>
    <div id="toc">
      <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%8E%9F%E7%90%86"><span class="toc-number">1.</span> <span class="toc-text">原理</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%A6%82%E4%BD%95%E4%BD%BF%E7%94%A8"><span class="toc-number">2.</span> <span class="toc-text">如何使用</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#model-conv1d-1level"><span class="toc-number">2.1.</span> <span class="toc-text">00-model-conv1d-1level</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#model-conv1d-2level"><span class="toc-number">2.2.</span> <span class="toc-text">01-model-conv1d-2level</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#model-conv1doutput-channels-2level"><span class="toc-number">2.3.</span> <span class="toc-text">02-model-conv1d+output
channels-2level</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#model-conv1doc-3level"><span class="toc-number">2.4.</span> <span class="toc-text">03-model-conv1d+oc-3level</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#model-conv1docic-3levelspatial"><span class="toc-number">2.5.</span> <span class="toc-text">04-model-conv1d+oc+ic-3levelspatial</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#mapper-conv1doc-3level"><span class="toc-number">2.6.</span> <span class="toc-text">05-mapper-conv1d+oc-3level</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#mapper-convlayer-eyeriss"><span class="toc-number">2.7.</span> <span class="toc-text">06-mapper-convlayer-eyeriss</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%9C%AA%E7%90%86%E8%A7%A3%E7%9A%84%E6%A6%82%E5%BF%B5"><span class="toc-number">2.8.</span> <span class="toc-text">未理解的概念</span></a></li></ol></li></ol>
    </div>
  </span>
</div>

    
    <div class="content index py4">
        
        <article class="post" itemscope itemtype="http://schema.org/BlogPosting">
  <header>
    
    <h1 class="posttitle" itemprop="name headline">
        TimeLoop
    </h1>



    <div class="meta">
      <span class="author" itemprop="author" itemscope itemtype="http://schema.org/Person">
        <span itemprop="name">JuneWen</span>
      </span>
      
    <div class="postdate">
      
        <time datetime="2023-03-16T03:58:08.000Z" itemprop="datePublished">2023-03-16</time>
        
      
    </div>


      
    <div class="article-category">
        <i class="fas fa-archive"></i>
        <a class="category-link" href="/categories/%E6%AF%95%E4%B8%9A%E8%AE%BE%E8%AE%A1/">毕业设计</a>
    </div>


      
    <div class="article-tag">
        <i class="fas fa-tag"></i>
        <a class="tag-link-link" href="/tags/DNN%E5%8A%A0%E9%80%9F%E5%99%A8/" rel="tag">DNN加速器</a>, <a class="tag-link-link" href="/tags/%E6%A8%A1%E6%8B%9F%E5%99%A8/" rel="tag">模拟器</a>
    </div>


    </div>
  </header>
  

  <div class="content" itemprop="articleBody">
    <p>作用：映射神经网络，找到最优的数据重用工作流。</p>
<h1 id="原理">原理</h1>
<figure>
<img src="/2023/03/16/TimeLoop/image-20230316120500047.png" alt="image-20230316120500047">
<figcaption aria-hidden="true">image-20230316120500047</figcaption>
</figure>
<h1 id="如何使用">如何使用</h1>
<h2 id="model-conv1d-1level">00-model-conv1d-1level</h2>
<p><img src="/2023/03/16/TimeLoop/image-20230215163226554.png" alt="image-20230215163226554" style="zoom: 25%;"></p>
<p>通过文件<code>timeloop-model.accelergy.log</code>可知，timeloop生成映射后会自动调用accelergy，将输入的architecture通过<code>catci</code>组件评估。</p>
<figure>
<img src="/2023/03/16/TimeLoop/image-20230215162913799.png" alt="image-20230215162913799">
<figcaption aria-hidden="true">image-20230215162913799</figcaption>
</figure>
<p>输出的读写次数不一样，<strong>因为第一次做MAC运算不用读只需写回结果？？？</strong>。</p>
<figure>
<img src="/2023/03/16/TimeLoop/image-20230215161827393.png" alt="image-20230215161827393">
<figcaption aria-hidden="true">image-20230215161827393</figcaption>
</figure>
<h2 id="model-conv1d-2level">01-model-conv1d-2level</h2>
<p><img src="/2023/03/16/TimeLoop/image-20230215164012799.png" alt="image-20230215164012799" style="zoom: 25%;"></p>
<p>定义了两种映射的方式，<code>output stationary</code>和<code>weight stationary</code>。</p>
<figure>
<img src="/2023/03/16/TimeLoop/image-20230215163758778.png" alt="image-20230215163758778">
<figcaption aria-hidden="true">image-20230215163758778</figcaption>
</figure>
<p>按照step4改成 3 1/1 1920之后，ws会报错：</p>
<figure>
<img src="/2023/03/16/TimeLoop/image-20230215170843695.png" alt="image-20230215170843695">
<figcaption aria-hidden="true">image-20230215170843695</figcaption>
</figure>
<p>改成 （2）3 64/1 30 后比<code>os</code>的 （1）1 1920/3 1
对比如下，能耗变大了。原因是，在比较小的3*16的计算中，所有的计算数和计算结果都能存储在buffer中，而计算量变大后（1）仍然可以在内层buffer中完成全部计算，由于是OS，每次mac只有一个数需要重新取，而（2）不是完全的WS，没算完30个output，都会再取一遍weight，从而多了63*3=189次的从mainMemory到buffer的weight数据读取.。。。</p>
<figure>
<img src="/2023/03/16/TimeLoop/image-20230215171153214.png" alt="image-20230215171153214">
<figcaption aria-hidden="true">image-20230215171153214</figcaption>
</figure>
<h2 id="model-conv1doutput-channels-2level">02-model-conv1d+output
channels-2level</h2>
<p>讨论了分块问题（tail）<img src="/2023/03/16/TimeLoop/image-20230215175930634.png" alt="image-20230215175930634"></p>
<p>buffer层的区别，主要在Input多读了一次进来</p>
<figure>
<img src="/2023/03/16/TimeLoop/image-20230225144923476.png" alt="image-20230225144923476">
<figcaption aria-hidden="true">image-20230225144923476</figcaption>
</figure>
<p>mainmemory的区别，也主要在input多读了一遍</p>
<figure>
<img src="/2023/03/16/TimeLoop/image-20230225145210890.png" alt="image-20230225145210890">
<figcaption aria-hidden="true">image-20230225145210890</figcaption>
</figure>
<h2 id="model-conv1doc-3level">03-model-conv1d+oc-3level</h2>
<figure>
<img src="/2023/03/16/TimeLoop/image-20230215181203973.png" alt="image-20230215181203973">
<figcaption aria-hidden="true">image-20230215181203973</figcaption>
</figure>
<p>讨论了bypass的问题，感觉这里bypass的作用其实是定义连接的方式，选择性地绕过某一个存储层，<strong>这里可以理解为RF直接和MM相联</strong>。</p>
<figure>
<img src="/2023/03/16/TimeLoop/image-20230225174724380.png" alt="image-20230225174724380">
<figcaption aria-hidden="true">image-20230225174724380</figcaption>
</figure>
<p>RegisterFile层的bypass：output数据从Main Memory到Register
File虽然经过了ClobalBuffer，但没有存储在其中，因而相比没有bypass，节省了读取GlobalBuffer的能量，但网络传输的能量未发生变化。</p>
<p>GLB层的bypass：Weight和Input读的次数显著提升，但省去了output的读取。</p>
<figure>
<img src="/2023/03/16/TimeLoop/image-20230225174059773.png" alt="image-20230225174059773">
<figcaption aria-hidden="true">image-20230225174059773</figcaption>
</figure>
<h2 id="model-conv1docic-3levelspatial">04-model-conv1d+oc+ic-3levelspatial</h2>
<figure>
<img src="/2023/03/16/TimeLoop/image-20230215181715931.png" alt="image-20230215181715931">
<figcaption aria-hidden="true">image-20230215181715931</figcaption>
</figure>
<p>问题：[C, K, R, P]</p>
<p>Timeloop自动检测并利用多播机会。</p>
<p><code>KP</code>: Output 分块, Input数据被自动的多播（从GLB到RF）</p>
<p><code>CP</code>：Input 分块,
Output数据被自动地多播（从GLB到RF），而Output数据存回时（从RF到GLB）可以先进行压缩再存回，与多播相反。观察输出文件，实际效果更差，因为分块了之后Output数据还要写回，而Input数据不用，所以这个策略能效较差。</p>
<h2 id="mapper-conv1doc-3level">05-mapper-conv1d+oc-3level</h2>
<p>2^(2*3) = 64 映射空间的大小？？？</p>
<p>mapper字段变成了下图所示，还有多了一个mapspace_constraints字段。</p>
<p><img src="/2023/03/16/TimeLoop/image-20230225220028110.png" alt="image-20230225220028110" style="zoom:50%;"></p>
<h2 id="mapper-convlayer-eyeriss">06-mapper-convlayer-eyeriss</h2>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">mapper:</span><br><span class="line">  optimization-metrics: [ delay, energy ]</span><br><span class="line">  live-status: False</span><br><span class="line">  num-threads: 8</span><br><span class="line">  timeout: 15000</span><br><span class="line">  victory-condition: 500</span><br><span class="line">  algorithm: random-pruned</span><br><span class="line">  max-permutations-per-if-visit: 16</span><br></pre></td></tr></table></figure>
<p>硬件架构和数据流的限制：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line">architecture_constraints:</span><br><span class="line">  targets:</span><br><span class="line">  # certain buffer only stores certain datatypes</span><br><span class="line">  - target: psum_spad</span><br><span class="line">    type: bypass</span><br><span class="line">    bypass: [Inputs, Weights]</span><br><span class="line">    keep: [Outputs]</span><br><span class="line">  - target: weights_spad</span><br><span class="line">    type: bypass</span><br><span class="line">    bypass: [Inputs, Outputs]</span><br><span class="line">    keep: [Weights]</span><br><span class="line">  - target: ifmap_spad</span><br><span class="line">    type: bypass</span><br><span class="line">    bypass: [Weights, Outputs]</span><br><span class="line">    keep: [Inputs]</span><br><span class="line">  - target: DummyBuffer</span><br><span class="line">    type: bypass</span><br><span class="line">    bypass: [Inputs, Outputs, Weights]</span><br><span class="line">  - target: shared_glb</span><br><span class="line">    type: bypass</span><br><span class="line">    bypass: [Weights]</span><br><span class="line">    keep: [Inputs, Outputs]</span><br><span class="line">  - target: DummyBuffer</span><br><span class="line">    type: spatial</span><br><span class="line">    split: 4</span><br><span class="line">    permutation: NPQR SCM</span><br><span class="line">    factors: N=1 P=1 Q=1 R=1 S=0</span><br><span class="line">  # only allow fanout of M, Q out from glb</span><br><span class="line">  - target: shared_glb</span><br><span class="line">    type: spatial</span><br><span class="line">    split: 7</span><br><span class="line">    permutation: NCPRSQM</span><br><span class="line">    factors: N=1 C=1 P=1 R=1 S=1</span><br><span class="line">  # one ofmap position but of different output channels</span><br><span class="line">  - target: psum_spad</span><br><span class="line">    type: temporal</span><br><span class="line">    permutation: NCPQRS M</span><br><span class="line">    factors: N=1 C=1 R=1 S=1 P=1 Q=1</span><br><span class="line">  # row stationary -&gt; 1 row at a time</span><br><span class="line">  - target: weights_spad</span><br><span class="line">    type: temporal</span><br><span class="line">    permutation: NMPQS CR</span><br><span class="line">    factors: N=1 M=1 P=1 Q=1 S=1 R=0</span><br><span class="line">  - target: ifmap_spad</span><br><span class="line">    type: temporal</span><br><span class="line">    permutation: NMCPQRS</span><br><span class="line">    factors: N=1 M=1 C=1 P=1 Q=1 R=1 S=1</span><br><span class="line">  # enforce the hardware limit of the bypassing everything</span><br><span class="line">  - target: DummyBuffer</span><br><span class="line">    type: temporal</span><br><span class="line">    factors: N=1 M=1 C=1 P=1 Q=1 R=1 S=1</span><br></pre></td></tr></table></figure>
<p>下面的约束不是硬件架构和数据流的限制，而是帮助限制搜索空间以加快搜索速度.</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">mapspace_constraints:</span><br><span class="line">  targets:</span><br><span class="line">    # intuitive optimization to reduce map space size</span><br><span class="line">    # the factors of these are 1 anyways, so the order does not really matter</span><br><span class="line">    - target: DummyBuffer</span><br><span class="line">      type: temporal</span><br><span class="line">      permutation: NMCPQRS</span><br><span class="line">    # intuitive optimization for row stationary</span><br><span class="line">    # -&gt; process a row/col of the output before going to the next one</span><br><span class="line">    - target: shared_glb</span><br><span class="line">      type: temporal</span><br><span class="line">      permutation: QRSC PNM</span><br><span class="line">      factors: Q=1 R=1 S=1 P=0</span><br><span class="line">    # intuitive optimization to reduce map space size</span><br><span class="line">    - target: DRAM</span><br><span class="line">      type: temporal</span><br><span class="line">      permutation: RSP CMNQ</span><br><span class="line">      factors: R=1 S=1 P=1</span><br></pre></td></tr></table></figure>
<h2 id="未理解的概念">未理解的概念</h2>
<p><code>timeloop-model.stats.txt</code></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">Temporal reductions</span><br><span class="line">per-instance</span><br><span class="line">per-cluster</span><br><span class="line">Fanout</span><br><span class="line">Multicast factor</span><br><span class="line">Average number of hops : 0.50</span><br><span class="line">Spatial Reduction Energy</span><br></pre></td></tr></table></figure>

  </div>
</article>



        
          <div id="footer-post-container">
  <div id="footer-post">

    <div id="nav-footer" style="display: none">
      <ul>
         
          <li><a href="/">首页</a></li>
         
          <li><a href="/about/">关于</a></li>
         
          <li><a href="/search/">搜索</a></li>
         
          <li><a href="/archives/">归档</a></li>
         
          <li><a href="/tags/">tags</a></li>
         
          <li><a href="/categories/">categories</a></li>
         
          <li><a target="_blank" rel="noopener" href="http://github.com/Junwen-Zhang">项目</a></li>
        
      </ul>
    </div>

    <div id="toc-footer" style="display: none">
      <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%8E%9F%E7%90%86"><span class="toc-number">1.</span> <span class="toc-text">原理</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%A6%82%E4%BD%95%E4%BD%BF%E7%94%A8"><span class="toc-number">2.</span> <span class="toc-text">如何使用</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#model-conv1d-1level"><span class="toc-number">2.1.</span> <span class="toc-text">00-model-conv1d-1level</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#model-conv1d-2level"><span class="toc-number">2.2.</span> <span class="toc-text">01-model-conv1d-2level</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#model-conv1doutput-channels-2level"><span class="toc-number">2.3.</span> <span class="toc-text">02-model-conv1d+output
channels-2level</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#model-conv1doc-3level"><span class="toc-number">2.4.</span> <span class="toc-text">03-model-conv1d+oc-3level</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#model-conv1docic-3levelspatial"><span class="toc-number">2.5.</span> <span class="toc-text">04-model-conv1d+oc+ic-3levelspatial</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#mapper-conv1doc-3level"><span class="toc-number">2.6.</span> <span class="toc-text">05-mapper-conv1d+oc-3level</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#mapper-convlayer-eyeriss"><span class="toc-number">2.7.</span> <span class="toc-text">06-mapper-convlayer-eyeriss</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%9C%AA%E7%90%86%E8%A7%A3%E7%9A%84%E6%A6%82%E5%BF%B5"><span class="toc-number">2.8.</span> <span class="toc-text">未理解的概念</span></a></li></ol></li></ol>
    </div>

    <div id="share-footer" style="display: none">
      <ul>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.facebook.com/sharer.php?u=http://example.com/2023/03/16/TimeLoop/"><i class="fab fa-facebook fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://twitter.com/share?url=http://example.com/2023/03/16/TimeLoop/&text=TimeLoop"><i class="fab fa-twitter fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.linkedin.com/shareArticle?url=http://example.com/2023/03/16/TimeLoop/&title=TimeLoop"><i class="fab fa-linkedin fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://pinterest.com/pin/create/bookmarklet/?url=http://example.com/2023/03/16/TimeLoop/&is_video=false&description=TimeLoop"><i class="fab fa-pinterest fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="mailto:?subject=TimeLoop&body=Check out this article: http://example.com/2023/03/16/TimeLoop/"><i class="fas fa-envelope fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://getpocket.com/save?url=http://example.com/2023/03/16/TimeLoop/&title=TimeLoop"><i class="fab fa-get-pocket fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://reddit.com/submit?url=http://example.com/2023/03/16/TimeLoop/&title=TimeLoop"><i class="fab fa-reddit fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.stumbleupon.com/submit?url=http://example.com/2023/03/16/TimeLoop/&title=TimeLoop"><i class="fab fa-stumbleupon fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://digg.com/submit?url=http://example.com/2023/03/16/TimeLoop/&title=TimeLoop"><i class="fab fa-digg fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.tumblr.com/share/link?url=http://example.com/2023/03/16/TimeLoop/&name=TimeLoop&description="><i class="fab fa-tumblr fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://news.ycombinator.com/submitlink?u=http://example.com/2023/03/16/TimeLoop/&t=TimeLoop"><i class="fab fa-hacker-news fa-lg" aria-hidden="true"></i></a></li>
</ul>

    </div>

    <div id="actions-footer">
        <a id="menu" class="icon" href="#" onclick="$('#nav-footer').toggle();return false;"><i class="fas fa-bars fa-lg" aria-hidden="true"></i> 菜单</a>
        <a id="toc" class="icon" href="#" onclick="$('#toc-footer').toggle();return false;"><i class="fas fa-list fa-lg" aria-hidden="true"></i> 目录</a>
        <a id="share" class="icon" href="#" onclick="$('#share-footer').toggle();return false;"><i class="fas fa-share-alt fa-lg" aria-hidden="true"></i> 分享</a>
        <a id="top" style="display:none" class="icon" href="#" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');"><i class="fas fa-chevron-up fa-lg" aria-hidden="true"></i> 返回顶部</a>
    </div>

  </div>
</div>

        
        <footer id="footer">
  <div class="footer-left">
    Copyright &copy;
    
    
    2023
    JuneWen
  </div>
  <div class="footer-right">
    <nav>
      <ul>
        <!--
       --><li><a href="/">首页</a></li><!--
     --><!--
       --><li><a href="/about/">关于</a></li><!--
     --><!--
       --><li><a href="/search/">搜索</a></li><!--
     --><!--
       --><li><a href="/archives/">归档</a></li><!--
     --><!--
       --><li><a href="/tags/">tags</a></li><!--
     --><!--
       --><li><a href="/categories/">categories</a></li><!--
     --><!--
       --><li><a target="_blank" rel="noopener" href="http://github.com/Junwen-Zhang">项目</a></li><!--
     -->
      </ul>
    </nav>
  </div>
</footer>

    </div>
    <!-- styles -->



  <link rel="preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.2/css/all.min.css" crossorigin="anonymous" onload="this.onload=null;this.rel='stylesheet'"/>


    <!-- jquery -->
 
  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.0/jquery.min.js" crossorigin="anonymous"></script> 




<!-- clipboard -->

  
    <script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.7/clipboard.min.js" crossorigin="anonymous"></script> 
  
  <script type="text/javascript">
  $(function() {
    // copy-btn HTML
    var btn = "<span class=\"btn-copy tooltipped tooltipped-sw\" aria-label=\"复制到粘贴板！\">";
    btn += '<i class="far fa-clone"></i>';
    btn += '</span>'; 
    // mount it!
    $(".highlight table").before(btn);
    var clip = new ClipboardJS('.btn-copy', {
      text: function(trigger) {
        return Array.from(trigger.nextElementSibling.querySelectorAll('.code')).reduce((str,it)=>str+it.innerText+'\n','')
      }
    });
    clip.on('success', function(e) {
      e.trigger.setAttribute('aria-label', "复制成功！");
      e.clearSelection();
    })
  })
  </script>


<script src="/js/main.js"></script>

<!-- search -->

<!-- Google Analytics -->

<!-- Baidu Analytics -->

  <script type="text/javascript">
        var _hmt = _hmt || [];
        (function() {
          var hm = document.createElement("script");
          hm.src = "https://hm.baidu.com/hm.js?7f1cdd299fd07fce81f0a77b5ee9e8c4";
          var s = document.getElementsByTagName("script")[0];
          s.parentNode.insertBefore(hm, s);
        })();
        </script>

<!-- Cloudflare Analytics -->

<!-- Umami Analytics -->

<!-- Disqus Comments -->

<!-- utterances Comments -->

</body>
</html>
